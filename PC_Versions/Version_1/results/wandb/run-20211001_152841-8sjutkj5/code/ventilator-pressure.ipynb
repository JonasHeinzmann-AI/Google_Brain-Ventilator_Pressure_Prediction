{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "- PyTorch RNN starter code with W&B  \n",
    "- Pytorch W&B Usage Examples from https://docs.wandb.ai/guides/integrations/pytorch  \n",
    "\n",
    "If this notebook is helpful, feel free to upvote :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/google/deluca-lung/main/assets/2020-10-02%20Ventilator%20diagram.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defs import TrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    competition='ventilator'\n",
    "    _wandb_kernel='nakama'\n",
    "    apex=False\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name='rnn'\n",
    "    scheduler='CosineAnnealingLR' # ['linear', 'cosine', 'ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    batch_scheduler=False\n",
    "    #num_warmup_steps=100 # ['linear', 'cosine']\n",
    "    #num_cycles=0.5 # 'cosine'\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=50 # CosineAnnealingLR\n",
    "    #T_0=50 # CosineAnnealingWarmRestarts\n",
    "    epochs=5\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    hidden_size=64\n",
    "    lr=5e-3\n",
    "    min_lr=1e-6\n",
    "    weight_decay=1e-6\n",
    "    batch_size=64\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    cate_seq_cols=['R', 'C']\n",
    "    cont_seq_cols=['time_step', 'u_in', 'u_out'] + ['breath_time', 'u_in_time']\n",
    "    train=True\n",
    "    inference=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if CFG.apex:\n",
    "    from apex import amp\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n",
      "Get your W&B access token from here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\heinz/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/anony-moose-140316/Ventilator-Pressure-Public?apiKey=2cddf237b244a7a18c9b07310860e6c2b2baea94\" target=\"_blank\">https://app.wandb.ai/anony-moose-140316/Ventilator-Pressure-Public?apiKey=2cddf237b244a7a18c9b07310860e6c2b2baea94</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/anony-moose-140316/Ventilator-Pressure-Public/runs/2p5vg0sf?apiKey=2cddf237b244a7a18c9b07310860e6c2b2baea94\" target=\"_blank\">https://app.wandb.ai/anony-moose-140316/Ventilator-Pressure-Public/runs/2p5vg0sf?apiKey=2cddf237b244a7a18c9b07310860e6c2b2baea94</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.12.3 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "import wandb\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "    wandb.login(key=secret_value_0)\n",
    "    anony = None\n",
    "except:\n",
    "    anony = \"must\"\n",
    "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "    \n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "run = wandb.init(project=\"Ventilator-Pressure-Public\", \n",
    "                 name=CFG.model_name,\n",
    "                 config=class2dict(CFG),\n",
    "                 group=CFG.model_name,\n",
    "                 job_type=\"train\",\n",
    "                 anonymous=anony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    score = mean_absolute_error(y_trues, y_preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080043</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>2.964399</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>3.157395</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>3.170056</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>3.271690</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out   pressure\n",
       "0   1          1  1  2   0.000000  0.080043      0   5.837492\n",
       "1   2          1  1  2   0.033652  2.964399      0   5.907794\n",
       "2   3          1  1  2   0.067514  3.157395      0   7.876254\n",
       "3   4          1  1  2   0.101542  3.170056      0  11.742872\n",
       "4   5          1  1  2   0.135756  3.271690      0  12.234987"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031904</td>\n",
       "      <td>2.141835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063827</td>\n",
       "      <td>2.750578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095751</td>\n",
       "      <td>3.101470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127644</td>\n",
       "      <td>3.307654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  breath_id  R  C  time_step      u_in  u_out\n",
       "0   1          0  0  1   0.000000  0.000000      0\n",
       "1   2          0  0  1   0.031904  2.141835      0\n",
       "2   3          0  0  1   0.063827  2.750578      0\n",
       "3   4          0  0  1   0.095751  3.101470      0\n",
       "4   5          0  0  1   0.127644  3.307654      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure\n",
       "0   1         0\n",
       "1   2         0\n",
       "2   3         0\n",
       "3   4         0\n",
       "4   5         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "for c in ['u_in']:\n",
    "    train[c] = np.log1p(train[c])\n",
    "    test[c] = np.log1p(test[c])\n",
    "    \n",
    "r_map = {5: 0, 20: 1, 50: 2}\n",
    "c_map = {10: 0, 20: 1, 50: 2}\n",
    "train['R'] = train['R'].map(r_map)\n",
    "test['R'] = test['R'].map(r_map)\n",
    "train['C'] = train['C'].map(c_map)\n",
    "test['C'] = test['C'].map(c_map)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# FE\n",
    "# ====================================================\n",
    "def add_feature(df):\n",
    "    # breath_time\n",
    "    df['breath_time'] = df['time_step'] - df['time_step'].shift(1)\n",
    "    df.loc[df['time_step'] == 0, 'breath_time'] = 0\n",
    "    # u_in_time\n",
    "    df['u_in_time'] = df['u_in'] - df['u_in'].shift(1)\n",
    "    df.loc[df['time_step'] == 0, 'u_in_time'] = 0\n",
    "    return df\n",
    "\n",
    "\n",
    "train = add_feature(train)\n",
    "test = add_feature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    1207200\n",
      "1    1207200\n",
      "2    1207200\n",
      "3    1207200\n",
      "4    1207200\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = GroupKFold(n_splits=5)\n",
    "groups = train['breath_id'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['pressure'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "print(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.hidden_size = cfg.hidden_size\n",
    "        self.r_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.c_emb = nn.Embedding(3, 2, padding_idx=0)\n",
    "        self.seq_emb = nn.Sequential(\n",
    "            nn.Linear(4 + len(cfg.cont_seq_cols), self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, \n",
    "                            dropout=0.2, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size * 2, self.hidden_size * 2),\n",
    "            nn.LayerNorm(self.hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.),\n",
    "            nn.Linear(self.hidden_size * 2, 1),\n",
    "        )\n",
    "        for n, m in self.named_modules():\n",
    "            if isinstance(m, nn.LSTM):\n",
    "                print(f'init {m}')\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        nn.init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        nn.init.normal_(param.data)\n",
    "            elif isinstance(m, nn.GRU):\n",
    "                print(f\"init {m}\")\n",
    "                for param in m.parameters():\n",
    "                    if len(param.shape) >= 2:\n",
    "                        init.orthogonal_(param.data)\n",
    "                    else:\n",
    "                        init.normal_(param.data)\n",
    "\n",
    "    def forward(self, cate_seq_x, cont_seq_x):\n",
    "        bs = cont_seq_x.size(0)\n",
    "        r_emb = self.r_emb(cate_seq_x[:,:,0]).view(bs, 80, -1)\n",
    "        c_emb = self.c_emb(cate_seq_x[:,:,1]).view(bs, 80, -1)\n",
    "        seq_x = torch.cat((r_emb, c_emb, cont_seq_x), 2)\n",
    "        seq_emb = self.seq_emb(seq_x)\n",
    "        seq_emb, _ = self.lstm(seq_emb)\n",
    "        output = self.head(seq_emb).view(bs, -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# helper function\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(train_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if CFG.apex:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   loss=losses,\n",
    "                   grad_norm=grad_norm,\n",
    "                   lr=scheduler.get_lr()[0],\n",
    "                   ))\n",
    "        wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    for step, (cate_seq_x, cont_seq_x, u_out, y) in enumerate(valid_loader):\n",
    "        loss_mask = u_out == 0\n",
    "        cate_seq_x, cont_seq_x, y = cate_seq_x.to(device), cont_seq_x.to(device), y.to(device)\n",
    "        batch_size = cont_seq_x.size(0)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        loss = 2. * criterion(pred[loss_mask], y[loss_mask]) + criterion(pred[loss_mask == 0], y[loss_mask == 0])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step, len(valid_loader),\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   loss=losses,\n",
    "                   ))\n",
    "    preds = np.concatenate(preds)\n",
    "    return losses.avg, preds\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for step, (cate_seq_x, cont_seq_x) in tk0:\n",
    "        cate_seq_x, cont_seq_x = cate_seq_x.to(device), cont_seq_x.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(cate_seq_x, cont_seq_x)\n",
    "        preds.append(pred.view(-1).detach().cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    y_true = valid_folds['pressure'].values\n",
    "    non_expiratory_phase_val_idx = valid_folds[valid_folds['u_out'] == 0].index # The expiratory phase is not scored\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds)\n",
    "    valid_dataset = TrainDataset(valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif CFG.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=CFG.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=CFG.num_cycles\n",
    "            )\n",
    "        elif CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # apex\n",
    "    # ====================================================\n",
    "    if CFG.apex:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(y_true[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - MAE Score (without expiratory phase): {score:.4f}')\n",
    "        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                   f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f\"fold{fold}_best.pth\")\n",
    "            \n",
    "    preds = torch.load(OUTPUT_DIR+f\"fold{fold}_best.pth\", map_location=torch.device('cpu'))['preds']\n",
    "    valid_folds['preds'] = preds\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare: 1.train 2.test\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df['pressure'].values\n",
    "        non_expiratory_phase_val_idx = result_df[result_df['u_out'] == 0].index # The expiratory phase is not scored\n",
    "        score = get_score(labels[non_expiratory_phase_val_idx], preds[non_expiratory_phase_val_idx])\n",
    "        LOGGER.info(f'Score (without expiratory phase): {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    \n",
    "    if CFG.inference:\n",
    "        test_dataset = TestDataset(test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
    "        for fold in CFG.trn_fold:\n",
    "            model = CustomModel(CFG)\n",
    "            path = OUTPUT_DIR+f\"fold{fold}_best.pth\"\n",
    "            state = torch.load(path, map_location=torch.device('cpu'))\n",
    "            model.load_state_dict(state['model'])\n",
    "            predictions = inference_fn(test_loader, model, device)\n",
    "            test[f'fold{fold}'] = predictions\n",
    "            del state, predictions; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        # submission\n",
    "        test['pressure'] = test[[f'fold{fold}' for fold in range(CFG.n_fold)]].mean(1)\n",
    "        test[['id', 'pressure']+[f'fold{fold}' for fold in range(CFG.n_fold)]].to_csv(OUTPUT_DIR+'raw_submission.csv', index=False)\n",
    "        test[['id', 'pressure']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LSTM(64, 64, batch_first=True, dropout=0.2, bidirectional=True)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
